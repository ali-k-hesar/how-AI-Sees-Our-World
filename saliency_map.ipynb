{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Function\n",
    "----------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def saliency_map(input_path,\n",
    "                 input_model,\n",
    "                 device: str = torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "                 target_label: int or float or np.array or torch.Tensor = torch.empty(0),\n",
    "                 visualize: bool = True):\n",
    "\n",
    "    # Check target type\n",
    "    if not isinstance(target_label, torch.Tensor):\n",
    "        target_label = torch.as_tensor(int(target_label)).unsqueeze(0)\n",
    "\n",
    "    # Load, normalize and convert image to torch.Tensor\n",
    "    input_image = plt.imread(input_path) / 255.\n",
    "    input_tensor = torch.from_numpy(input_image).permute(2, 0, 1).unsqueeze(0).float().requires_grad_().to(device)\n",
    "\n",
    "    # loss function is needed for computing loss and derivative with respect to input image\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # push model to eval mode and make all parameters requires_grad to false (only input image needs gradient)\n",
    "    input_model.to(device)\n",
    "    input_model.eval()\n",
    "    for p in input_model.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # Forward: use model output as target! (in model we trust)\n",
    "    y_hat = model(input_tensor)\n",
    "    y_true = torch.argmax(y_hat).unsqueeze(0) if not target_label.numel() else target_label\n",
    "    loss = criterion(y_hat, y_true)\n",
    "\n",
    "    # Compute gradient of loss with respect to input image\n",
    "    input_grad = torch.autograd.grad(loss, input_tensor)[0][0].detach().cpu()\n",
    "\n",
    "    # Only magnitude of gradients are needed\n",
    "    input_grad.abs_()\n",
    "\n",
    "    # Normalize gradients for visualization\n",
    "    input_grad = (input_grad - input_grad.min()) / (input_grad.max() - input_grad.min())\n",
    "\n",
    "    if visualize:\n",
    "        plt.imshow(input_grad.sum(0), alpha=0.8, cmap='hot')\n",
    "        plt.imshow(input_image, alpha=0.2)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return input_grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "image_path = \"pics/golden_retriever_1.jpeg\"\n",
    "_ = saliency_map(image_path, model, visualize=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step by Step\n",
    "----------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = models.resnet18(pretrained=True).to(device)\n",
    "model.eval()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image = plt.imread(\"pics/golden_retriever_1.jpeg\") / 255.\n",
    "input_tensor = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float().requires_grad_().to(device)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "y_true = torch.tensor([285], dtype=torch.int64)\n",
    "print(y_true.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_hat = model(input_tensor)\n",
    "loss = criterion(y_hat, torch.argmax(y_hat).unsqueeze(0))\n",
    "\n",
    "input_grad = torch.autograd.grad(loss, input_tensor)[0][0].detach().cpu()\n",
    "print(input_grad.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_grad.abs_()\n",
    "input_grad = (input_grad - input_grad.min()) / (input_grad.max() - input_grad.min())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(input_grad.sum(0), alpha=0.7, cmap='jet')\n",
    "plt.imshow(image, alpha=0.3)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(input_grad.sum(0), alpha=0.8, cmap='hot')\n",
    "plt.imshow(image, alpha=0.2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(input_grad.permute(1, 2, 0), cmap='hot')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}